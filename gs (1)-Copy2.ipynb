{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np                                                       \n",
    "import pandas\n",
    "URL = 'MAIN.csv'                   \n",
    "df_train = pandas.read_csv(URL)\n",
    "df_char = pandas.read_csv('ML_Bond_metadata_corrected_dates.csv')\n",
    "df_tr = df_train[:]\n",
    "df_ch  = df_char[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Direc = {}\n",
    "for i in range(len(df_char['isin'])):\n",
    "    Direc[df_char['isin'].values[i]] = []\n",
    "    for j in list(df_char.columns.values)[1:]:\n",
    "        Direc[df_char['isin'].values[i]].append(df_char[j].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tr.drop_duplicates()\n",
    "DAY = []\n",
    "MONTH = []\n",
    "for i in range(len(df_tr)):\n",
    "    DAY.append(int(''.join(list(df_tr['time'].values[i].split()[1])[:-5])))\n",
    "    MONTH.append(''.join(list(df_tr['time'][i].split()[1])[-5:-2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowshik\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Kowshik\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df_tr['DAY'] = DAY\n",
    "df_tr['MONTH'] = MONTH\n",
    "df_tr_S = df_tr[df_tr.side != 'S']\n",
    "df_tr_B = df_tr[df_tr.side != 'B']\n",
    "df_tr_S = df_tr_S.drop_duplicates()\n",
    "df_tr_B = df_tr_B.drop_duplicates()\n",
    "df_tr_S = df_tr_S[['isin','side','price','DAY','MONTH','volume']]\n",
    "df_tr_B = df_tr_B[['isin','side','price','DAY','MONTH','volume']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grouped = df_tr_S.groupby(['isin','DAY','MONTH'])\n",
    "df_tr_b = df_tr_S.groupby(['isin','DAY','MONTH'], as_index=False).sum()\n",
    "df_tr_s= df_tr_B.groupby(['isin','DAY','MONTH'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DONOT DISTURB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_B = df_tr_b['volume'].values\n",
    "Y_S = df_tr_s['volume'].values\n",
    "del df_tr_s['volume'] \n",
    "del df_tr_b['volume']\n",
    "del df_tr_s['price'] \n",
    "del df_tr_b['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "test_set = df_ch['isin']\n",
    "df_train_1 = DataFrame({'isin': test_set})\n",
    "df_train_2 = DataFrame({'isin': test_set})\n",
    "df_train_3 = DataFrame({'isin': test_set})\n",
    "df_train_1['DAY'] = 10\n",
    "df_train_2['DAY'] = 13\n",
    "df_train_3['DAY'] = 14\n",
    "df_train_1['MONTH'] = 'Jun'\n",
    "df_train_2['MONTH'] = 'Jun'\n",
    "df_train_3['MONTH'] = 'Jun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Attributes = {}\n",
    "for j in range(2,23):#,len(list(df_char.columns.values))):\n",
    "    Attributes[j] = []\n",
    "    for i in  df_tr_b['isin'].values:\n",
    "        Attributes[j].append(Direc[i][j])\n",
    "    df_tr_b[list(df_char.columns.values)[j]] = Attributes[j]\n",
    "    \n",
    "Attributes = {}\n",
    "for j in range(2,23):#,len(list(df_char.columns.values))):\n",
    "    Attributes[j] = []\n",
    "    for i in  df_tr_s['isin'].values:\n",
    "        Attributes[j].append(Direc[i][j])\n",
    "    df_tr_s[list(df_char.columns.values)[j]] = Attributes[j]\n",
    "    \n",
    "Attributes = {}\n",
    "for j in range(2,23):#,len(list(df_char.columns.values))):\n",
    "    Attributes[j] = []\n",
    "    for i in  df_train_1['isin'].values:\n",
    "        Attributes[j].append(Direc[i][j])\n",
    "    df_train_1[list(df_char.columns.values)[j]] = Attributes[j]\n",
    "    df_train_2[list(df_char.columns.values)[j]] = Attributes[j]  \n",
    "    df_train_3[list(df_char.columns.values)[j]] = Attributes[j]  \n",
    "df_Tr_b=df_tr_b.dropna(axis=1,how='any')\n",
    "df_Tr_s=df_tr_s.dropna(axis=1,how='any')\n",
    "df_Train_1=df_train_1.dropna(axis=1,how='any')\n",
    "df_Train_2=df_train_2.dropna(axis=1,how='any')\n",
    "df_Train_3=df_train_3.dropna(axis=1,how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df_Train_1['isin'] \n",
    "del df_Tr_b['isin']\n",
    "del df_Tr_s['isin']\n",
    "del df_Train_2['isin'] \n",
    "del df_Train_3['isin']\n",
    "#del df_tr_b['MONTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = {}\n",
    "for i in list(df_tr_b.columns.values):\n",
    "    k[i] =  len(np.unique(df_tr_b[i].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'144aFlag': 27,\n",
       " 'DAY': 31,\n",
       " 'MONTH': 4,\n",
       " 'amtIssued': 4058,\n",
       " 'amtOutstanding': 33,\n",
       " 'collateralType': 1767,\n",
       " 'couponFrequency': 8,\n",
       " 'couponType': 76,\n",
       " 'industryGroup': 11,\n",
       " 'industrySector': 363,\n",
       " 'issueDate': 4,\n",
       " 'market': 2534,\n",
       " 'maturity': 19,\n",
       " 'maturityType': 8,\n",
       " 'paymentRank': 2,\n",
       " 'ratingAgency1EffectiveDate': 24,\n",
       " 'ratingAgency1Rating': 4,\n",
       " 'ratingAgency2Rating': 4,\n",
       " 'securityType': 11}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = ['DAY','amtIssued','collateralType','couponFrequency','paymentRank','ratingAgency1Rating','securityType','issueDate']\n",
    "df_tr_b = df_Tr_b[A][:]\n",
    "df_tr_s = df_Tr_s[A][:]\n",
    "df_train_1 = df_Train_1[A][:]\n",
    "df_train_2 = df_Train_2[A][:]\n",
    "df_train_3 = df_Train_3[A][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ENCODING\n",
    "X_train = df_tr_b.to_dict('records')\n",
    "X_test_1 = df_train_1.to_dict('records')\n",
    "X_test_2 = df_train_2.to_dict('records')\n",
    "X_test_3 = df_train_3.to_dict('records')\n",
    "X_tr = []\n",
    "X_te_1 = []\n",
    "X_te_2 = []\n",
    "X_te_3 = []\n",
    "X_tr.extend(X_train)\n",
    "X_te_1.extend(X_test_1)\n",
    "X_te_2.extend(X_test_2)\n",
    "X_te_3.extend(X_test_3)\n",
    "X_total = X_tr + X_te_1+ X_te_2+ X_te_3\n",
    "#One Hot Encoding \n",
    "from sklearn.feature_extraction import DictVectorizer  \n",
    "enc = DictVectorizer()\n",
    "X_encoded_total =enc.fit_transform(X_total)\n",
    "X_encoded_train =X_encoded_total[:len(X_tr)]\n",
    "X_encoded_test_1 =X_encoded_total[len(X_tr):len(X_tr)+len(X_te_1)]\n",
    "X_encoded_test_2 =X_encoded_total[len(X_tr)+len(X_te_1):len(X_tr)+len(X_te_1)+len(X_te_2)]\n",
    "X_encoded_test_3 =X_encoded_total[len(X_tr)+len(X_te_1)+len(X_te_2):len(X_tr)+len(X_te_1)+len(X_te_2)+len(X_te_3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<323986x32 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 2586090 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1, loss='ls',\n",
       "             max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extra Trees\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.ensemble import GradientBoostingRegressor,ExtraTreesRegressor,BaggingRegressor\n",
    "reg1 = GradientBoostingRegressor()\n",
    "reg1.fit(X_encoded_train.toarray(),Y_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_B_1 = reg1.predict(X_encoded_test_1.toarray())\n",
    "Y_B_2 = reg1.predict(X_encoded_test_2.toarray())\n",
    "Y_B_3 = reg1.predict(X_encoded_test_3.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ENCODING\n",
    "X_train = df_tr_s.to_dict('records')\n",
    "X_test_1 = df_train_1.to_dict('records')\n",
    "X_test_2 = df_train_2.to_dict('records')\n",
    "X_test_3 = df_train_3.to_dict('records')\n",
    "X_tr = []\n",
    "X_te_1 = []\n",
    "X_te_2 = []\n",
    "X_te_3 = []\n",
    "X_tr.extend(X_train)\n",
    "X_te_1.extend(X_test_1)\n",
    "X_te_2.extend(X_test_2)\n",
    "X_te_3.extend(X_test_3)\n",
    "X_total = X_tr + X_te_1+ X_te_2+ X_te_3\n",
    "#One Hot Encoding \n",
    "from sklearn.feature_extraction import DictVectorizer  \n",
    "enc = DictVectorizer()\n",
    "X_encoded_total =enc.fit_transform(X_total)\n",
    "X_encoded_train =X_encoded_total[:len(X_tr)]\n",
    "X_encoded_test_1 =X_encoded_total[len(X_tr):len(X_tr)+len(X_te_1)]\n",
    "X_encoded_test_2 =X_encoded_total[len(X_tr)+len(X_te_1):len(X_tr)+len(X_te_1)+len(X_te_2)]\n",
    "X_encoded_test_3 =X_encoded_total[len(X_tr)+len(X_te_1)+len(X_te_2):len(X_tr)+len(X_te_1)+len(X_te_2)+len(X_te_3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extra Trees\n",
    "from sklearn.ensemble import RandomForestRegressor    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor,ExtraTreesRegressor,BaggingRegressor\n",
    "reg1 = GradientBoostingRegressor()\n",
    "reg1.fit(X_encoded_train.toarray(),Y_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_S_1 = reg1.predict(X_encoded_test_1.toarray())\n",
    "Y_S_2 = reg1.predict(X_encoded_test_2.toarray())\n",
    "Y_S_3 = reg1.predict(X_encoded_test_3.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ans1 = DataFrame({'isin':test_set })\n",
    "df_ans1['buyvolume'] = Y_B_1+Y_B_2+Y_B_3\n",
    "df_ans1['sellvolume'] = Y_S_1+Y_S_2+Y_S_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ans1.to_csv('11.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1105159.31415687,   759674.85787521,   223382.71095787, ...,\n",
       "        1450841.54080754,  2190655.6379427 ,  1828888.14984272])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.,   0.,   1.,   0.,   0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded_test.toarray()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
